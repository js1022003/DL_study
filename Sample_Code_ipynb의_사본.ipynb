{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sample_Code.ipynb의 사본",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/js1022003/DL_study/blob/main/Sample_Code_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2022 소프트웨어중심대학 공동 딥러닝 챌린지\n",
        "\n",
        "\n",
        "이 노트북은 2022 소프트웨어 중심대학 공동 딥러닝 챌린지를 위한 샘플코드 입니다.\n",
        "이 코드를 구동하기 위해선 [Kaggle](https://www.kaggle.com/competitions/2022swunivchallenge/data)에서 데이터를 다운 받아 구글드라이브에 저장해서 실행해야 합니다. \n",
        "\n",
        "샘플코드는 Train 데이터셋을 이용한 모델 학습, Test 데이터셋에 대한 예측파일 (`submission.csv`) 저장으로 구성 되어 있습니다. 만들어진 `submission.csv`파일을 챌린지에 제출하시면 됩니다. 그리고 샘플코드는 단순한 예시 코드이므로 코드를 새로 작성하거나 모델이나 파라미터를 변경해서 사용하시면 됩니다.\n",
        "\n",
        "---\n",
        "\n",
        "샘플코드의 구성은 다음과 같습니다.\n",
        "1. [Import Pakage](#scrollTo=b_B7smvmLaqQ)\n",
        "2. [Argument Setting](#scrollTo=RSdu8EhUP5Dn)\n",
        "3. [Checking Challenge Dataset](#scrollTo=pKn2ce-oR3Ne)\n",
        "4. [Model Configuration](#scrollTo=lG00xINwJymW)\n",
        "5. [Train Model & Test](#scrollTo=O1og1N7OgbBR)\n",
        "\n",
        "\n",
        "챌린지를 위해서 도움이 될수 있는 사이트들을 소개합니다.\n",
        "\n",
        "- [Deep Learning Zero To All:Pytorch](https://deeplearningzerotoall.github.io/season2/lec_pytorch.html): 딥러닝에 대한 기초내용을 배울 수 있습니다.\n",
        "- [Dealing files Colab](https://neptune.ai/blog/google-colab-dealing-with-files) : 코랩에서 데이터를 다루는것을 배울 수 있습니다.\n",
        "- [pytorch tutorial](https://pytorch.org/tutorials/) : 파이토치 기초에 대해 배울 수 있습니다.\n",
        "- [image classification tutorial](https://github.com/bentrevett/pytorch-image-classification) : 이미지 분류 문제에 대한 기본을 배울 수 있습니다.\n",
        "- [timm github](https://github.com/rwightman/pytorch-image-models): 사전 학습된 최신 모델 (SOTA)를 자유롭게 사용할 수 있는 라이브러리 입니다.\n",
        "\n",
        "That's all. Now start your awesome work! 😁"
      ],
      "metadata": {
        "id": "9au8IFfaQN8I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data download**"
      ],
      "metadata": {
        "id": "1NTlCGOS8j_H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle\n",
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "ZGFnb8mf8jUM",
        "outputId": "13fd1387-6e72-44ae-ee70-dd5385c41f72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2022.6.15)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (6.1.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.64.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-5fedafe9-1021-4292-bbab-7a1356526c0e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-5fedafe9-1021-4292-bbab-7a1356526c0e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"junseokimm\",\"key\":\"0b1c49edd8207915882035f1a861a63c\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "QizgRxYa9NHP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c 2022swunivchallenge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tr0WIntJ9koX",
        "outputId": "e80836cf-16de-4fa7-c8cc-5703f1a3d4b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 2022swunivchallenge.zip to /content\n",
            " 94% 194M/205M [00:06<00:00, 22.7MB/s]\n",
            "100% 205M/205M [00:06<00:00, 32.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip 2022swunivchallenge.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-Wa-Tu09rIY",
        "outputId": "c3875a90-d764-4568-b39d-433504155fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  2022swunivchallenge.zip\n",
            "  inflating: dataset/test/features.npy  \n",
            "  inflating: dataset/train/features.npy  \n",
            "  inflating: dataset/train/labels.npy  \n",
            "  inflating: submission.csv          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.Import Package\n",
        "샘플코드에 사용된 패키지들을 불러옵니다."
      ],
      "metadata": {
        "id": "b_B7smvmLaqQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzGbH29EPzW4"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import datetime\n",
        "import easydict\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import SGD, AdamW\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Argument Setting\n",
        "학습에 사용될 파라미터들을 설정합니다.  \n",
        "**(중요)데이터셋 경로를 본인에게 맞게 변경해주세요.**"
      ],
      "metadata": {
        "id": "RSdu8EhUP5Dn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "args = easydict.EasyDict({\n",
        "    # device setting\n",
        "    'device': 0,\n",
        "    'seed' : 123,\n",
        "    \n",
        "    # training setting\n",
        "    'batch_size' : 64,\n",
        "    'num_workers' : 2,\n",
        "    'epoch' : 20,\n",
        "    \n",
        "    # optimizer & criterion\n",
        "    'lr' : 0.01,\n",
        "    'momentum' : 0.9,\n",
        "    'weight_decay' : 1e-4,\n",
        "    'nesterov' : True,\n",
        "    \n",
        "    # directory\n",
        "    'data_path' : '/content/dataset',\n",
        "    'save_path' : '/content/submission',\n",
        "    # etc\n",
        "    'print_freq' : 30,\n",
        "    'threshold' : 0.5,\n",
        "})\n",
        "\n",
        "def setup(args):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    if args.seed is not None:\n",
        "        random.seed(args.seed)\n",
        "        np.random.seed(args.seed)\n",
        "        torch.random.manual_seed(args.seed)\n",
        "    return device"
      ],
      "metadata": {
        "id": "7IjRMEDNRxgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Checking the Dataset\n",
        "학습에 사용될 데이터를 불러와서 데이터의 구성을 확인합니다.\n",
        "```\n",
        "Train Data의 개수: 8,000               Train Data의 Shape: (2048, 7, 7)\n",
        "Test Data의 개수 : 8,00                Test Data의 Shape: (2048, 7, 7)\n",
        "Class의 개수: 80\n",
        "```"
      ],
      "metadata": {
        "id": "pKn2ce-oR3Ne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(args, data_type:str='train'):\n",
        "    \"\"\"\n",
        "    data_type(str): train or test\n",
        "    \"\"\"\n",
        "    start = time.time()\n",
        "    data_path = Path(args.data_path) / data_type\n",
        "    features = np.load(data_path/'features.npy')\n",
        "    if data_type == 'test':\n",
        "        labels = np.zeros_like(features)  # dummy test label\n",
        "    else:\n",
        "        labels = np.load(data_path/'labels.npy')\n",
        "    end = time.time()\n",
        "    sec = end - start\n",
        "    print(f\"Completed Loading {data_type} data at {str(datetime.timedelta(seconds=sec)).split('.')[0]}\")\n",
        "    return features, labels"
      ],
      "metadata": {
        "id": "-WCmQkE2SnOZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load train_data\n",
        "train_data, train_label = load_data(args, 'train')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnzPBrfmUSyi",
        "outputId": "c7c956a7-1bbe-4f26-a3c6-b657fa655a51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed Loading train data at 0:00:01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load test data\n",
        "test_data, test_label = load_data(args, 'test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBpdTA_STGPG",
        "outputId": "0063bb2e-a272-45cd-a2aa-652b9900c623"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed Loading test data at 0:00:00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check dataset shape\n",
        "args.num_features = train_data.shape[1]\n",
        "args.num_classes = len(np.unique(train_label))\n",
        "print(f\"Train_shape: {train_data.shape}\")\n",
        "print(f\"Test_shape: {test_data.shape}\")\n",
        "print(f\"Number of classes: {len(np.unique(train_label))}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oH4WM5QUO5x",
        "outputId": "1ea872da-f7ed-4a6d-e356-1c2ce2876899"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train_shape: (8000, 2048, 7, 7)\n",
            "Test_shape: (800, 2048, 7, 7)\n",
            "Number of classes: 80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check label_data shape\n",
        "print(train_label.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kad1F0tdUhKz",
        "outputId": "9fd28cfc-9117-41cd-e8e0-61ff58034054"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Model configuration\n",
        "* Dataset: 챌린지 데이터셋을 사용하여 DataLoader에 적용하기 위한 클래스\n",
        "* SampleModel: BottleNeck 구조의 Conv Model\n",
        "* SampleModel2: 임의로 생성한 Conv Model\n",
        "* SampleModel3: 단순 Classifier Model \n"
      ],
      "metadata": {
        "id": "lG00xINwJymW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset:\n",
        "    def __init__(self, features, labels, transform=None):\n",
        "        \"\"\"Basic Dataset Class\n",
        "        \n",
        "        :arg\n",
        "            features: numpy array(features)\n",
        "            labels: numpy asrray(labels)\n",
        "        \"\"\"\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "        self.classes = np.unique(self.labels)\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        feature = self.features[idx]\n",
        "        \n",
        "        if self.transform:\n",
        "            feature = self.transform(feature)\n",
        "        \n",
        "        label = self.labels[idx]\n",
        "        return feature, label\n",
        "\n",
        "class SampleModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=2048, out_channels=4096, kernel_size=1, stride=1)\n",
        "        self.bn1 = nn.BatchNorm2d(4096)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(in_channels=4096, out_channels=1024, kernel_size=1, stride=1)\n",
        "        self.bn2 = nn.BatchNorm2d(1024)\n",
        "        self.conv3 = nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, stride=1, padding=1)\n",
        "        self.conv4 = nn.Conv2d(in_channels=1024, out_channels=4096, kernel_size=1, stride=1)\n",
        "        self.bn3 = nn.BatchNorm2d(4096)\n",
        "        \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "    \n",
        "        self.fc1 = nn.Linear(4096, 80)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv3(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv4(x)\n",
        "        x = self.bn3(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        \n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "    \n",
        "class SampleModel2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=2048, out_channels=1024, kernel_size=3, stride=2, padding=2)\n",
        "        self.bn1 = nn.BatchNorm2d(1024)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=3, stride=2, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(512)\n",
        "        \n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc1 = nn.Linear(512,80)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.maxpool(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        \n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "    \n",
        "class SampleModel3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
        "        self.fc1 = nn.Linear(2048, 80)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.avgpool(x)\n",
        "        x = torch.flatten(x,1)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "5qkQU-TuJxin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Train Model & Test\n",
        "챌린지 데이터를 샘플모델로 학습시키고 테스트데이터를 예측해 submission.csv를 저장"
      ],
      "metadata": {
        "id": "O1og1N7OgbBR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Metric:\n",
        "    def __init__(self, header='', fmt='{val:.4f} ({avg:.4f})'):\n",
        "        \"\"\"Base Metric Class \n",
        "        :arg\n",
        "            fmt(str): format representing metric in string\n",
        "        \"\"\"\n",
        "        self.val = 0\n",
        "        self.sum = 0\n",
        "        self.n = 0\n",
        "        self.avg = 0\n",
        "        self.header = header\n",
        "        self.fmt = fmt\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        if isinstance(val, torch.Tensor):\n",
        "            val = val.detach().clone()\n",
        "\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.n += n\n",
        "        self.avg = self.sum / self.n\n",
        "\n",
        "    def compute(self):\n",
        "        return self.avg\n",
        "\n",
        "    def __str__(self):\n",
        "        return self.header + ' ' + self.fmt.format(**self.__dict__)\n",
        "    \n",
        "def train_one_epoch(model, train_dataloader, optimizer, criterion, epoch, args):\n",
        "    # 1. create metric\n",
        "    data_m = Metric(header='Data:')\n",
        "    batch_m = Metric(header='Batch:')\n",
        "    loss_m = Metric(header='Loss:')\n",
        "\n",
        "    # 2. start validate\n",
        "    model.train()\n",
        "\n",
        "    total_iter = len(train_dataloader)\n",
        "    start_time = time.time()\n",
        "\n",
        "    for batch_idx, (x, y) in enumerate(train_dataloader):\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        x = x.to(args.device)\n",
        "        y = y.to(args.device)\n",
        "\n",
        "        data_m.update(time.time() - start_time)\n",
        "\n",
        "        y_hat = model(x)\n",
        "        loss = criterion(y_hat, y)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss_m.update(loss, batch_size)\n",
        "\n",
        "        if batch_idx and args.print_freq and batch_idx % args.print_freq == 0:\n",
        "            num_digits = len(str(total_iter))\n",
        "            print(f\"TRAIN({epoch:03}): [{batch_idx:>{num_digits}}/{total_iter}] {batch_m} {data_m} {loss_m}\")\n",
        "\n",
        "        batch_m.update(time.time() - start_time)\n",
        "        start_time = time.time()\n",
        "\n",
        "    # 3. calculate metric\n",
        "    duration = str(datetime.timedelta(seconds=batch_m.sum)).split('.')[0]\n",
        "    data = str(datetime.timedelta(seconds=data_m.sum)).split('.')[0]\n",
        "    f_b_o = str(datetime.timedelta(seconds=batch_m.sum - data_m.sum)).split('.')[0]\n",
        "    loss = loss_m.compute()\n",
        "\n",
        "    # 4. print metric\n",
        "    space = 16\n",
        "    num_metric = 5\n",
        "    print('-'*space*num_metric)\n",
        "    print((\"{:>16}\"*num_metric).format('Stage', 'Batch', 'Data', 'F+B+O', 'Loss'))\n",
        "    print('-'*space*num_metric)\n",
        "    print(f\"{'TRAIN('+str(epoch)+')':>{space}}{duration:>{space}}{data:>{space}}{f_b_o:>{space}}{loss:{space}.4f}\")\n",
        "    print('-'*space*num_metric)\n",
        "\n",
        "    return loss\n",
        "\n",
        "def prediction_mask(output, args):\n",
        "    \"\"\"\n",
        "    학습된 모델이 예측한 값이 Threshold 값을 넘지 못하면 Train에 없던 데이터로 판단하여 -1 라벨로 예측하도록 지정\n",
        "    \"\"\"\n",
        "    prediction = torch.argsort(output, dim=-1, descending=True)\n",
        "    mask = F.softmax(output).max(dim=-1)[0] < args.threshold\n",
        "    prediction[mask,0] = -1\n",
        "    prediction = prediction[:, :min(1, output.size(1))].squeeze(-1).tolist()\n",
        "    return prediction\n",
        "\n",
        "def prediction_submission(predict, args):\n",
        "    \"\"\"\n",
        "    테스트 데이터의 idx와 예측한 prediction label을 submission.csv로 저장\n",
        "    \"\"\"\n",
        "    submission = [[idx, label] for idx, label in enumerate(predict)]\n",
        "    df = pd.DataFrame(data=submission, columns=['id_idx', 'label'], index=None)\n",
        "    args.save_path = Path(args.save_path)\n",
        "    args.save_path.mkdir(exist_ok=True)\n",
        "    df.to_csv(args.save_path / 'submission.csv', index=False)\n",
        "\n",
        "def test_submission(model, test_dataloader, args):\n",
        "    \"\"\"\n",
        "    학습한 모델로 테스트 데이터의 라벨을 예측하고 그 결과를 submission.csv로 저장\n",
        "    \"\"\"\n",
        "    model_predict = [] # for submission.csv\n",
        "    for x,y in test_dataloader:\n",
        "        x = x.to(args.device)\n",
        "        y = y.to(args.device)\n",
        "        output = model(x)\n",
        "        prediction = prediction_mask(output, args)\n",
        "        model_predict.extend(prediction)\n",
        "    prediction_submission(model_predict, args)"
      ],
      "metadata": {
        "id": "oFpo85CjekuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.models as models"
      ],
      "metadata": {
        "id": "W8r6PSA7oPfB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run(args):\n",
        "    start = time.time()\n",
        "    \n",
        "    # 1. load train, test dataset\n",
        "    train_dataset = Dataset(train_data, train_label)\n",
        "    test_dataset = Dataset(test_data, test_label)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers)\n",
        "    test_dataloader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False, num_workers=args.num_workers)\n",
        "    \n",
        "    # 2. create model\n",
        "    # model = SampleModel().to(args.device)\n",
        "    model= models.mobilenet_v3()\n",
        "\n",
        "    # 3. optimizer, criterion\n",
        "    # optimizer = SGD(model.parameters(), lr=args.lr, momentum=args.momentum, weight_decay=args.weight_decay, nesterov=args.nesterov)\n",
        "    optimizer = AdamW(model.parameters())\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    \n",
        "    # 4. train & validate\n",
        "    for epoch in range(args.epoch):\n",
        "        train_loss = train_one_epoch(model, train_dataloader, optimizer, criterion, epoch, args)\n",
        "    \n",
        "    test_submission(model, test_dataloader, args)\n",
        "    end = time.time()\n",
        "    sec = end - start\n",
        "    print(f\"Finished Training & Test at {str(datetime.timedelta(seconds=sec)).split('.')[0]} ....\")"
      ],
      "metadata": {
        "id": "sUUiUAqtGrTR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "setup(args)\n",
        "run(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "3JXPLogcGs9_",
        "outputId": "d8451fa8-7b3e-4687-c2e9-6ae3f6d9dac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-a485bdeb1a0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-41-0836e5856c32>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# 2. create model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# model = SampleModel().to(args.device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmobilenet_v3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# 3. optimizer, criterion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torchvision.models' has no attribute 'mobilenet_v3'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check submission.csv\n",
        "pd.read_csv(args.save_path / 'submission.csv', index_col=False)"
      ],
      "metadata": {
        "id": "S7V-oSgM7mFX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}